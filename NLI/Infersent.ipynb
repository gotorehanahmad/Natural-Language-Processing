{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir GloVe\n",
    "# !curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "# !unzip GloVe/glove.840B.300d.zip -d GloVe/\n",
    "# !mkdir fastText\n",
    "# !curl -Lo fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
    "# !unzip fastText/crawl-300d-2M.vec.zip -d fastText/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir encoder\n",
    "# !curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
    "# !curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rehan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferSent(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(InferSent, self).__init__()\n",
    "        self.bsize = config['bsize']\n",
    "        self.word_emb_dim = config['word_emb_dim']\n",
    "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
    "        self.pool_type = config['pool_type']\n",
    "        self.dpout_model = config['dpout_model']\n",
    "        self.version = 1 if 'version' not in config else config['version']\n",
    "\n",
    "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
    "                                bidirectional=True, dropout=self.dpout_model)\n",
    "\n",
    "        assert self.version in [1, 2]\n",
    "        if self.version == 1:\n",
    "            self.bos = '<s>'\n",
    "            self.eos = '</s>'\n",
    "            self.max_pad = True\n",
    "            self.moses_tok = False\n",
    "        elif self.version == 2:\n",
    "            self.bos = '<p>'\n",
    "            self.eos = '</p>'\n",
    "            self.max_pad = False\n",
    "            self.moses_tok = True\n",
    "\n",
    "    def is_cuda(self):\n",
    "        # either all weights are on cpu or they are on gpu\n",
    "        return self.enc_lstm.bias_hh_l0.data.is_cuda\n",
    "\n",
    "    def forward(self, sent_tuple):\n",
    "        # sent_len: [max_len, ..., min_len] (bsize)\n",
    "        # sent: (seqlen x bsize x worddim)\n",
    "        sent, sent_len = sent_tuple\n",
    "\n",
    "        # Sort by length (keep idx)\n",
    "        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
    "        sent_len_sorted = sent_len_sorted.copy()\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    "\n",
    "        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n",
    "            else torch.from_numpy(idx_sort)\n",
    "        sent = sent.index_select(1, idx_sort)\n",
    "\n",
    "        # Handling padding in Recurrent Networks\n",
    "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\n",
    "        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\n",
    "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
    "\n",
    "        # Un-sort by length\n",
    "        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n",
    "            else torch.from_numpy(idx_unsort)\n",
    "        sent_output = sent_output.index_select(1, idx_unsort)\n",
    "\n",
    "        # Pooling\n",
    "        if self.pool_type == \"mean\":\n",
    "            sent_len = torch.FloatTensor(sent_len.copy()).unsqueeze(1).cuda()\n",
    "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
    "            emb = emb / sent_len.expand_as(emb)\n",
    "        elif self.pool_type == \"max\":\n",
    "            if not self.max_pad:\n",
    "                sent_output[sent_output == 0] = -1e9\n",
    "            emb = torch.max(sent_output, 0)[0]\n",
    "            if emb.ndimension() == 3:\n",
    "                emb = emb.squeeze(0)\n",
    "                assert emb.ndimension() == 2\n",
    "\n",
    "        return emb\n",
    "\n",
    "    def set_w2v_path(self, w2v_path):\n",
    "        self.w2v_path = w2v_path\n",
    "\n",
    "    def get_word_dict(self, sentences, tokenize=True):\n",
    "        # create vocab of words\n",
    "        word_dict = {}\n",
    "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = ''\n",
    "        word_dict[self.bos] = ''\n",
    "        word_dict[self.eos] = ''\n",
    "        return word_dict\n",
    "\n",
    "    def get_w2v(self, word_dict):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # create word_vec with w2v vectors\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path) as f:\n",
    "            for line in f:\n",
    "                word, vec = line.split(' ', 1)\n",
    "                if word in word_dict:\n",
    "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "        print('Found %s(/%s) words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
    "        return word_vec\n",
    "\n",
    "    def get_w2v_k(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # create word_vec with k first w2v vectors\n",
    "        k = 0\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path) as f:\n",
    "            for line in f:\n",
    "                word, vec = line.split(' ', 1)\n",
    "                if k <= K:\n",
    "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "                    k += 1\n",
    "                if k > K:\n",
    "                    if word in [self.bos, self.eos]:\n",
    "                        word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "\n",
    "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
    "                    break\n",
    "        return word_vec\n",
    "\n",
    "    def build_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "        self.word_vec = self.get_w2v(word_dict)\n",
    "        print('Vocab size : %s' % (len(self.word_vec)))\n",
    "\n",
    "    # build w2v vocab with k most frequent words\n",
    "    def build_vocab_k_words(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        self.word_vec = self.get_w2v_k(K)\n",
    "        print('Vocab size : %s' % (K))\n",
    "\n",
    "    def update_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
    "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "\n",
    "        # keep only new words\n",
    "        for word in self.word_vec:\n",
    "            if word in word_dict:\n",
    "                del word_dict[word]\n",
    "\n",
    "        # udpate vocabulary\n",
    "        if word_dict:\n",
    "            new_word_vec = self.get_w2v(word_dict)\n",
    "            self.word_vec.update(new_word_vec)\n",
    "        else:\n",
    "            new_word_vec = []\n",
    "        print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
    "\n",
    "    def get_batch(self, batch):\n",
    "        # sent in batch in decreasing order of lengths\n",
    "        # batch: (bsize, max_len, word_dim)\n",
    "        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n",
    "\n",
    "        for i in range(len(batch)):\n",
    "            for j in range(len(batch[i])):\n",
    "                embed[j, i, :] = self.word_vec[batch[i][j]]\n",
    "\n",
    "        return torch.FloatTensor(embed)\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        if self.moses_tok:\n",
    "            s = ' '.join(word_tokenize(s))\n",
    "            s = s.replace(\" n't \", \"n 't \")  # HACK to get ~MOSES tokenization\n",
    "            return s.split()\n",
    "        else:\n",
    "            return word_tokenize(s)\n",
    "\n",
    "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
    "        sentences = [[self.bos] + s.split() + [self.eos] if not tokenize else\n",
    "                     [self.bos] + self.tokenize(s) + [self.eos] for s in sentences]\n",
    "        n_w = np.sum([len(x) for x in sentences])\n",
    "\n",
    "        # filters words without w2v vectors\n",
    "        for i in range(len(sentences)):\n",
    "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
    "            if not s_f:\n",
    "                import warnings\n",
    "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. \\\n",
    "                               Replacing by \"</s>\"..' % (sentences[i], i))\n",
    "                s_f = [self.eos]\n",
    "            sentences[i] = s_f\n",
    "\n",
    "        lengths = np.array([len(s) for s in sentences])\n",
    "        n_wk = np.sum(lengths)\n",
    "        if verbose:\n",
    "            print('Nb words kept : %s/%s (%.1f%s)' % (\n",
    "                        n_wk, n_w, 100.0 * n_wk / n_w, '%'))\n",
    "\n",
    "        # sort by decreasing length\n",
    "        lengths, idx_sort = np.sort(lengths)[::-1], np.argsort(-lengths)\n",
    "        sentences = np.array(sentences)[idx_sort]\n",
    "\n",
    "        return sentences, lengths, idx_sort\n",
    "\n",
    "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
    "        tic = time.time()\n",
    "        sentences, lengths, idx_sort = self.prepare_samples(\n",
    "                        sentences, bsize, tokenize, verbose)\n",
    "\n",
    "        embeddings = []\n",
    "        for stidx in range(0, len(sentences), bsize):\n",
    "            batch = self.get_batch(sentences[stidx:stidx + bsize])\n",
    "            if self.is_cuda():\n",
    "                batch = batch.cuda()\n",
    "            with torch.no_grad():\n",
    "                batch = self.forward((batch, lengths[stidx:stidx + bsize])).data.cpu().numpy()\n",
    "            embeddings.append(batch)\n",
    "        embeddings = np.vstack(embeddings)\n",
    "\n",
    "        # unsort\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    "        embeddings = embeddings[idx_unsort]\n",
    "\n",
    "        if verbose:\n",
    "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
    "                    len(embeddings)/(time.time()-tic),\n",
    "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
    "        return embeddings\n",
    "\n",
    "    def visualize(self, sent, tokenize=True):\n",
    "\n",
    "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
    "        sent = [[self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]]\n",
    "\n",
    "        if ' '.join(sent[0]) == '%s %s' % (self.bos, self.eos):\n",
    "            import warnings\n",
    "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing \\\n",
    "                           by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
    "        batch = self.get_batch(sent)\n",
    "\n",
    "        if self.is_cuda():\n",
    "            batch = batch.cuda()\n",
    "        output = self.enc_lstm(batch)[0]\n",
    "        output, idxs = torch.max(output, 0)\n",
    "        # output, idxs = output.squeeze(), idxs.squeeze()\n",
    "        idxs = idxs.data.cpu().numpy()\n",
    "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
    "\n",
    "        # visualize model\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(12,12))\n",
    "        x = range(len(sent[0]))\n",
    "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
    "        plt.xticks(x, sent[0], rotation=45)\n",
    "        plt.bar(x, y)\n",
    "        plt.ylabel('%')\n",
    "        plt.title('Visualisation of words importance')\n",
    "        plt.show()\n",
    "\n",
    "        return output, idxs, argmaxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 2\n",
    "MODEL_PATH = \"encoder/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferSent(params_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'GloVe/glove.840B.300d.txt' if model_version == 1 else 'fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9815\n"
     ]
    }
   ],
   "source": [
    "# Load some sentences\n",
    "sentences = []\n",
    "with open('samples.txt') as f:\n",
    "    for line in f:\n",
    "        sentences.append(line.strip())\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 127563/130068 (98.1%)\n",
      "Speed : 48.0 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 9815\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences, bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"everyone hate you\"\n",
    "text2 = \"people despise you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86680156"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(model.encode([text1])[0], model.encode([text2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-6dcc1ecf3d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "idx = randint(0, len(sentences))\n",
    "_, _ = model.visualize(sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
